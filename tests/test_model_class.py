import os
import time
import unittest

import numpy as np
import tensorflow as tf

if 230 <= int(''.join(tf.__version__.split('.')[0:2]).ljust(3, '0')) < 250:
    from ai4water.functional import Model
    print(f"Switching to functional API due to tensorflow version {tf.__version__}")
else:
    from ai4water import Model

from ai4water.datasets import arg_beach
from ai4water.utils.utils import find_best_weight
from ai4water.functional import Model as FModel
from ai4water.preprocessing.datahandler import DataHandler
from ai4water._optimize import make_space
from ai4water.utils.utils import process_config_dict
from ai4water.utils.utils import find_opt_paras_from_model_config
from ai4water.hyperopt import Categorical, Real, Integer

data = arg_beach()
dh = DataHandler(data=data, verbosity=0)
x, y = dh.training_data()

mlp_model = {"layers": {"Dense": 8, "Dense_1": 1}}


def get_lstm():

    m_conf = {"layers": {"LSTM": {"config": {"units": Integer(2, 5, num_samples=10)}},
                         "relu": {},
                         "Dense_0": {"units": Integer(2, 5, name="dense1_units", num_samples=10),
                                     "activation": Categorical(["relu", "tanh"], name="dense1_act")},
                         "Dense_1": {"config": {"units": 1, "activation": "relu"}}}}
    return m_conf


def test_user_defined_data(_model):
    # using user defined x
    t, p = _model.predict(x=x, return_true=True)
    assert t is None
    assert len(p) == len(x)

    # using user defined x and y, post_processing must happen
    t, p = _model.predict(x=x, y=y, return_true=True)
    assert len(t) == len(p) == len(y)

    return


def _test_ml_inbuilt_data(_model):
    model = _model(model="RandomForestRegressor",
                   data=arg_beach(),
                   verbosity=0)
    model.fit()

    test_user_defined_data(model)

    t, p = model.predict(return_true=True)
    assert len(t) == len(p)
    return


def _test_ml_userdefined_data(_model):
    model = _model(model="RandomForestRegressor", verbosity=0)
    model.fit(x=x, y=y)

    test_user_defined_data(model)

    return model


def _test_fit(_model):
    model = _model(model="RandomForestRegressor", verbosity=0)
    model.fit(x, y)

    model.fit(x, y=y)

    model.fit(x=x, y=y)
    return


def _test_ml_userdefined_non_kw(_model):
    # using non-keyword arguments to .predict
    model = _model(model="RandomForestRegressor", verbosity=0)
    model.fit(x=x, y=y)

    model.predict(x)
    return


def _test_hydro_metrics(_model):
    model = _model(model="RandomForestRegressor", verbosity=0)
    model.fit(x=x, y=y)

    for metrics in ["minimal", "hydro_metrics", "all"]:
        model.predict(x=x, metrics=metrics)
    return


def _test_from_config_basic(_model, find_best=False, config_file=False):

    for m in ["RandomForestRegressor",
              "XGBRegressor",
              "CatBoostRegressor",
              "LGBMRegressor",
              mlp_model
              ]:
        model = _model(model=m, data=arg_beach(), lookback=1, verbosity=0)
        model.fit(x, y)
        ini_y = model.predict(np.arange(13).reshape(-1, 13)).item()

        if config_file:
            m2 = Model.from_config_file(os.path.join(model.path, 'config.json'))
        else:
            m2 = Model.from_config(model.config)

        best_weight = None
        if find_best:
            best_weight = os.path.join(model.w_path, find_best_weight(model.w_path))

        m2.update_weights(best_weight)
        fin_y = m2.predict(np.arange(13).reshape(-1, 13)).item()
        assert np.allclose(ini_y, fin_y)
        time.sleep(1)

    return


class TestPredictMethod(unittest.TestCase):

    def test_ml_inbuilt_data(self):
        _test_ml_inbuilt_data(Model)
        return

    def test_ml_inbuilt_data_fn(self):
        _test_ml_inbuilt_data(FModel)
        return

    def test_ml_userdefined_data(self):
        model = _test_ml_userdefined_data(Model)
        # using data generated by DataHnadler
        self.assertRaises(ValueError, model.predict)
        return

    def test_ml_userdefined_data_fn(self):
        model = _test_ml_userdefined_data(FModel)
        # using data generated by DataHnadler
        self.assertRaises(ValueError, model.predict)
        return

    def test_ml_userdefined_non_kw(self):
        _test_ml_userdefined_non_kw(Model)
        return

    def test_ml_userdefined_non_kw_fn(self):
        _test_ml_userdefined_non_kw(FModel)
        return

    def test_hydro_metrics(self):
        _test_hydro_metrics(Model)
        return

    def test_hydro_metrics_functional(self):
        _test_hydro_metrics(FModel)
        return


class TestFit(unittest.TestCase):

    def test_fit(self):
        _test_fit(Model)
        return

    def test_fit_functional(self):
        _test_fit(FModel)
        return


class TestFromConfig(unittest.TestCase):

    def test_subclassing(self):
        _test_from_config_basic(Model)
        return

    def test_subclassing_fn(self):
        _test_from_config_basic(FModel)

    def test_subclassing_with_weights(self):
        _test_from_config_basic(Model, find_best=True)

    def test_subclassing_fn_with_weights(self):
        # we are able to load functinoal model
        _test_from_config_basic(FModel, find_best=True)

    def test_subclassing_with_config_file(self):
        # we are able to load subclassing Model from config_file
        _test_from_config_basic(Model, config_file=True)
        return

    def test_fn_with_config_file(self):
        # we are able to load functional model from config_file
        _test_from_config_basic(FModel, config_file=True)
        return


class TestOptimize(unittest.TestCase):

    def test_optimize_transformations(self):

        df = arg_beach(inputs=["tide_cm", "wat_temp_c", "rel_hum"])

        setattr(Model, 'from_check_point', False)
        model = Model(model="XGBRegressor", data=df)

        model.optimize_transformations(exclude="tide_cm", algorithm="random", num_iterations=3)
        assert isinstance(model.config['transformation'], list)
        return

    def test_make_space(self):
        space = make_space(data.columns.to_list(), categories=['log', 'log2', 'minmax', 'none'])
        assert len(space) == 14
        # include
        space = make_space(data.columns.to_list(), include="tide_cm",
                           categories=['log', 'log2', 'minmax', 'none'])
        assert len(space) == 1

        include = ["tide_cm", "tetx_coppml"]
        space = make_space(data.columns.to_list(), include=include,
                           categories=['log', 'log2', 'minmax', 'none'])
        for sp, _name in zip(space, include):
            assert sp.name == _name

        exclude = "tide_cm"
        space = make_space(data.columns.to_list(), exclude=exclude,
                           categories=['log', 'log2', 'minmax', 'none'])
        for sp in space:
            assert sp.name != exclude

        exclude = ["tide_cm", "tetx_coppml"]
        space = make_space(data.columns.to_list(), exclude=exclude,
                           categories=['log', 'log2', 'minmax', 'none'])
        for sp in space:
            assert sp.name not in exclude

        new = {"tetx_coppml": ["log", "log2", "log10"]}
        space = make_space(data.columns.to_list(), include="tetx_coppml", append=new,
                           categories=['log', 'log2', 'minmax', 'none', 'log10'])
        assert len(space) == 1, space
        assert len(space[0].categories) == 3
        return


class TestOptimizeHyperparas(unittest.TestCase):
    config = {"XGBRegressor": {"n_estimators": Integer(low=10, high=20, num_samples=10),
                               "max_depth": Categorical([10, 20, 30]),
                               "learning_rate": Real(0.00001, 0.1, num_samples=10)}}

    def test_no_opt_paras(self):
        conf = "XGBRegressor"
        c, op, _ = find_opt_paras_from_model_config(conf)
        assert len(op) == 0
        return

    def test_no_opt_paras1(self):
        config = {"XGBRegressor": {"n_estimators": 2, "max_depth": 23}}
        c, op, _ = find_opt_paras_from_model_config(config)
        assert len(op) == 0
        return

    def test_ml(self):
        setattr(Model, 'from_check_point', False)
        model = Model(model=self.config,
                      verbosity=0,
                      data=arg_beach())
        optimizer = model.optimize_hyperparameters()
        s = set([v['n_estimators'] for v in optimizer.xy_of_iterations().values()])
        assert len(s) > 5  # assert that all suggestions are not same
        op = os.path.join(os.getcwd(), optimizer.opt_path)
        fname = os.path.join(op, "convergence.png")
        assert os.path.exists(fname)

        # make sure that model's config has been updated
        for k, v in optimizer.best_paras().items():
            assert model.config['model']['XGBRegressor'][k] == v
        return

    def test_ml_without_procesisng_results(self):
        setattr(Model, 'from_check_point', False)

        # without process results
        model = Model(model=self.config,
                      verbosity=0,
                      data=arg_beach())
        optimizer = model.optimize_hyperparameters(algorithm="random", num_iterations=3,
                                                   process_results=False)
        op = os.path.join(os.getcwd(), optimizer.opt_path)
        fname = os.path.join(op, "convergence.png")
        assert not os.path.exists(fname)

        # make sure that model's config has been updated
        for k, v in optimizer.best_paras().items():
            assert model.config['model']['XGBRegressor'][k] == v
        return

    def test_without_model(self):
        m_conf = None
        c, op, _ = find_opt_paras_from_model_config(m_conf)
        assert c is None and len(op) == 0

        return

    def test_nn_without_space(self):
        m_conf = {"layers": {"LSTM": 64}}
        c, op = process_config_dict(m_conf)
        assert len(m_conf['layers']) == 1
        assert len(op) == 0

        # with multi layers
        m_conf = {"layers":
                      {"LSTM": 64,
                       "Dense": 1}}
        assert len(m_conf['layers']) == 2
        assert len(op) == 0

        # multi layers with empty config
        m_conf = {"layers":
                      {"LSTM": 64,
                       "ReLu": {},
                       "Dense": 1}}
        c, op = process_config_dict(m_conf)
        assert len(m_conf['layers']) == 3
        assert len(op) == 0

        return

    def test_nn_with_space(self):
        # with space
        m_conf = {"layers": {"LSTM": Integer(32, 64)}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"units": Integer(32, 64)}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"units": Integer(32, 64)},
                             "Dense": 1}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"units": Integer(32, 64)},
                             "Dense": {"units": 1}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"units": Integer(32, 64)},
                             "Dense": {"units": 1, "activation": "relu"}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"units": Integer(32, 64)},
                             "relu": {},
                             "Dense": {"units": 1, "activation": "relu"}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['units'], int)
        assert len(op) == 1

        return

    def test_nn_with_config_kw(self):
        # with config keyword argument
        m_conf = {"layers": {"LSTM": {"config": {"units": Integer(32, 64)}}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['config']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"config": {"units": Integer(32, 64)}},
                             "Dense": 1}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['config']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM": {"config": {"units": Integer(32, 64)}},
                             "Dense": {"config": {"units": 1}}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['config']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM":  {"config": {"units": Integer(32, 64)}},
                             "Dense": {"config": {"units": 1, "activation": "relu"}}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['config']['units'], int)
        assert len(op) == 1

        m_conf = {"layers": {"LSTM":  {"config": {"units": Integer(32, 64), "activation": "relu"}},
                             "relu": {},
                             "Dense": {"config": {"units": 1, "activation": "relu"}}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['config']['units'], int)
        assert len(op) == 1
        return

    def test_nn_multiple_opt_paras(self):
        # multiple hpo arguments in multiple layers
        m_conf = {"layers": {"LSTM":  {"config": {"units": Integer(32, 64), "activation": "relu"}},
                             "relu": {},
                             "Dense1": {"units": Integer(10, 20, name="dense1_units"),
                                        "activation": Categorical(["relu", "tanh"], name="dense1_act")},
                             "Dense": {"config": {"units": 1, "activation": "relu"}}}}
        c, op = process_config_dict(m_conf)
        assert isinstance(c['layers']['LSTM']['config']['units'], int)
        assert len(op) == 3
        return

    def test_raise_duplicate_name_error(self):
        # duplication error
        m_conf = {"layers": {"LSTM":  {"config": {"units": Integer(32, 64), "activation": "relu"}},
                             "relu": {},
                             "Dense1": {"units": Integer(10, 20),
                                        "activation": Categorical(["relu", "tanh"], name="dense1_act")}}}
        self.assertRaises(ValueError, process_config_dict, m_conf)
        return

    def test_nn_complex(self):

        m_conf ={
            "Input": {'config': {'shape': (15, 8), 'name': "MyInputs"}},
            "LSTM": {'config': {'units': Integer(32, 64, name="lstm_units"),
                                'return_sequences': True, 'return_state': True, 'name': 'MyLSTM1'},
                     'inputs': 'MyInputs',
                     'outputs': ['junk', 'h_state', 'c_state']},

            "Dense_0": {'config': {'units': 1, 'name': 'MyDense'},
                        'inputs': 'h_state'},

            "Conv1D_1": {'config': {'filters': Integer(32, 64), 'kernel_size': 3, 'name': 'myconv'},
                         'inputs': 'junk'},
            "MaxPool1D": {'config': {'name': 'MyMaxPool'},
                          'inputs': 'myconv'},
            "Flatten": {'config': {'name': 'MyFlatten'},
                        'inputs': 'MyMaxPool'},

            "LSTM_3": {"config": {'units': Integer(32, 64, name="lsmt3_units"), 'name': 'MyLSTM2'},
                       'inputs': 'MyInputs',
                       'call_args': {'initial_state': ['h_state', 'c_state']}},

            "Concatenate": {'config': {'name': 'MyConcat'},
                            'inputs': ['MyDense', 'MyFlatten', 'MyLSTM2']},

            "Dense": 1
        }
        c, op = process_config_dict(m_conf)
        assert len(op) == 3
        return

    def test_nn_optimize(self):

        m_conf = get_lstm()

        setattr(Model, 'from_check_point', False)

        model = Model(model=m_conf,
                      data=arg_beach(),
                      verbosity=0,
                      epochs=5)

        print(model.path, 'model.path')
        optimizer = model.optimize_hyperparameters(algorithm="random", num_iterations=5, process_results=False)
        s = set([v['units'] for v in optimizer.xy_of_iterations().values()])
        assert len(s) >= 3  # assert that all suggestions are not same

        # make sure that model's config has been updated
        assert model.config['model']['layers']['LSTM']['config']['units'] == optimizer.best_paras()['units']
        assert model.config['model']['layers']['Dense_0']['activation'] == optimizer.best_paras()['dense1_act']
        assert model.config['model']['layers']['Dense_0']['units'] == optimizer.best_paras()['dense1_units']

        return

    def test_optimize_with_model_and_other_paras(self):
        # test that model_config and other in config such as lookback can also be optimzied
        m_conf = get_lstm()

        setattr(Model, 'from_check_point', False)

        model = Model(model=m_conf,
                      data=arg_beach(),
                      lookback=Integer(3, 10, num_samples=10),
                      verbosity=0,
                      epochs=5)

        optimizer = model.optimize_hyperparameters(algorithm="random", num_iterations=5, process_results=False)
        assert model.config['model']['layers']['LSTM']['config']['units'] == optimizer.best_paras()['units']
        assert model.config['lookback'] == optimizer.best_paras()['lookback']
        return


class TestEvaluate(unittest.TestCase):
    model = Model(
        model={"layers": {"Dense": 1}},
        lookback=1,
        data=arg_beach(),
        verbosity=0,
    )

    def test_basic(self):
        eval_scores = self.model.evaluate()
        assert isinstance(eval_scores, list) and len(eval_scores) == 2
        return

    def test_basic_with_metrics(self):
        # basic example with metrics
        eval_scores = self.model.evaluate(metrics="kge")
        assert isinstance(eval_scores, float)

    def test_basic_with_metric_groups(self):
        # basic example with metrics
        eval_scores = self.model.evaluate(metrics="hydro_metrics")
        assert isinstance(eval_scores, dict)
        return

    def test_custom_xy(self):
        eval_scores = self.model.evaluate(np.random.random((10, 13)), np.random.random((10, 1, 1)))
        assert isinstance(eval_scores, list) and len(eval_scores) == 2
        return

    def test_custom_xy0(self):
        # only y as keyword
        eval_scores = self.model.evaluate(np.random.random((10, 13)), y=np.random.random((10, 1, 1)))
        assert isinstance(eval_scores, list) and len(eval_scores) == 2
        return

    def test_custom_xy_as_keyword_args(self):
        eval_scores = self.model.evaluate(x=np.random.random((10, 13)), y=np.random.random((10, 1, 1)))
        assert isinstance(eval_scores, list) and len(eval_scores) == 2
        return

    def test_custom_xy_with_metrics(self):
        # custom data with metrics
        pbias = self.model.evaluate(x=np.random.random((10, 13)), y=np.random.random((10, 1, 1)),
                                    metrics='pbias')
        assert isinstance(pbias, float)
        return

    def test_custom_xy_with_metric_groups(self):
        # custom data with group of metrics
        hydro = self.model.evaluate(x=np.random.random((10, 13)), y=np.random.random((10, 1, 1)),
                                    metrics='hydro_metrics')
        assert isinstance(hydro, dict)
        return


if __name__ == "__main__":

    unittest.main()
